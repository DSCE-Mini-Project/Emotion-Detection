{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PHbDOD_OgZr3"
   },
   "outputs": [],
   "source": [
    "\n",
    "import librosa\n",
    "from librosa import display\n",
    "\n",
    "data, sampling_rate = librosa.load('D:/mini project/Models/examples1.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "id": "WSBABK1_gduf",
    "outputId": "582db6ff-c868-4d58-ed49-ed104f501a3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "% pylab inline\n",
    "\n",
    "import pandas as pd\n",
    "import glob \n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "igbWzvh7glJA",
    "outputId": "d3d07963-77d0-4953-a6bf-15671cefd08f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data loaded. Loading time: 90.42879271507263 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "path = 'D:/mini project/Models/features/'\n",
    "lst=[]\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for subdir, dirs, files in os.walk(path):\n",
    "      for file in files:\n",
    "        if file[7:8] in ['2','3','4','5']:\n",
    "            try:\n",
    "                X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
    "                mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
    "       \n",
    "                file = int(file[7:8]) - 1 \n",
    "                arr = mfccs, file\n",
    "                lst.append(arr)\n",
    "   \n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dwKRS8FLguSh"
   },
   "outputs": [],
   "source": [
    " X, y = zip(*lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3xePxgPVhUnc",
    "outputId": "cc78c577-db4f-4759-da1e-a1c293a22d22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2704, 40), (2704,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "iAyghTZdhWg_"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "X_name = 'X.joblib'\n",
    "y_name = 'y.joblib'\n",
    "save_dir = 'D:/mini project/Models/joblib_features'\n",
    "\n",
    "savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
    "savedy = joblib.dump(y, os.path.join(save_dir, y_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "u-SidlfKrCn0"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "X = joblib.load('D:/mini project/Models/joblib_features/X.joblib')\n",
    "y = joblib.load('D:/mini project/Models/joblib_features/y.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "K-z4cFqar2zb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "Bf_2elz6r-7h"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_traincnn = np.expand_dims(X_train, axis=2)\n",
    "x_testcnn = np.expand_dims(X_test, axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O2vMnLI5sWAW",
    "outputId": "bff33354-7d3f-4280-c647-6f2e9f2eb2cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1811, 40, 1), (893, 40, 1))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_traincnn.shape, x_testcnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "nDqVAD8_sXy7"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.layers import Input, Flatten, Dropout, Activation\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same',\n",
    "                 input_shape=(40,1)))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('softmax'))\n",
    "opt = tensorflow.keras.optimizers.RMSprop(learning_rate=0.00001, rho=0.9, epsilon=None, decay=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "anhBteS_sbAb",
    "outputId": "4b481bb4-ed5d-4564-a99d-a952bc8a0690"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 40, 128)           768       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 5, 128)            82048     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 5128      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 87,944\n",
      "Trainable params: 87,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "wdP9AzTNtJni"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCC_I3vEtMNZ",
    "outputId": "2b144b94-d284-4ef9-ed33-aab992aa6727"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 5.2254 - accuracy: 0.2391 - val_loss: 1.5773 - val_accuracy: 0.3449\n",
      "Epoch 2/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 1.2529 - accuracy: 0.4660 - val_loss: 1.1404 - val_accuracy: 0.5073\n",
      "Epoch 3/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 1.0882 - accuracy: 0.5356 - val_loss: 1.0681 - val_accuracy: 0.5207\n",
      "Epoch 4/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 1.0092 - accuracy: 0.5748 - val_loss: 1.0267 - val_accuracy: 0.5521\n",
      "Epoch 5/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.9554 - accuracy: 0.5875 - val_loss: 0.9612 - val_accuracy: 0.5857\n",
      "Epoch 6/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.9199 - accuracy: 0.6118 - val_loss: 0.9462 - val_accuracy: 0.5655\n",
      "Epoch 7/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.8921 - accuracy: 0.6218 - val_loss: 0.8998 - val_accuracy: 0.6025\n",
      "Epoch 8/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.8767 - accuracy: 0.6256 - val_loss: 0.8761 - val_accuracy: 0.6159\n",
      "Epoch 9/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.8566 - accuracy: 0.6229 - val_loss: 0.9310 - val_accuracy: 0.5610\n",
      "Epoch 10/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.8416 - accuracy: 0.6433 - val_loss: 0.8384 - val_accuracy: 0.6473\n",
      "Epoch 11/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.8221 - accuracy: 0.6472 - val_loss: 0.8764 - val_accuracy: 0.6260\n",
      "Epoch 12/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.8120 - accuracy: 0.6654 - val_loss: 0.8168 - val_accuracy: 0.6461\n",
      "Epoch 13/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.7933 - accuracy: 0.6687 - val_loss: 0.8814 - val_accuracy: 0.6148\n",
      "Epoch 14/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.7887 - accuracy: 0.6709 - val_loss: 0.8215 - val_accuracy: 0.6517\n",
      "Epoch 15/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.7793 - accuracy: 0.6731 - val_loss: 0.8352 - val_accuracy: 0.6316\n",
      "Epoch 16/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.7607 - accuracy: 0.6759 - val_loss: 0.7948 - val_accuracy: 0.6596\n",
      "Epoch 17/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.7544 - accuracy: 0.6908 - val_loss: 0.8283 - val_accuracy: 0.6573\n",
      "Epoch 18/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.7459 - accuracy: 0.6919 - val_loss: 0.8258 - val_accuracy: 0.6484\n",
      "Epoch 19/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.7408 - accuracy: 0.6902 - val_loss: 0.8751 - val_accuracy: 0.6159\n",
      "Epoch 20/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.7339 - accuracy: 0.6935 - val_loss: 0.7310 - val_accuracy: 0.6842\n",
      "Epoch 21/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.7267 - accuracy: 0.6991 - val_loss: 0.8156 - val_accuracy: 0.6484\n",
      "Epoch 22/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.7243 - accuracy: 0.6969 - val_loss: 0.7526 - val_accuracy: 0.6797\n",
      "Epoch 23/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.7173 - accuracy: 0.7046 - val_loss: 0.7846 - val_accuracy: 0.6506\n",
      "Epoch 24/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.7068 - accuracy: 0.7101 - val_loss: 0.7398 - val_accuracy: 0.6820\n",
      "Epoch 25/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.7071 - accuracy: 0.7051 - val_loss: 0.7769 - val_accuracy: 0.6607\n",
      "Epoch 26/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6969 - accuracy: 0.7068 - val_loss: 0.8250 - val_accuracy: 0.6383\n",
      "Epoch 27/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6924 - accuracy: 0.7167 - val_loss: 0.7351 - val_accuracy: 0.6976\n",
      "Epoch 28/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6929 - accuracy: 0.7129 - val_loss: 0.7750 - val_accuracy: 0.6461\n",
      "Epoch 29/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6819 - accuracy: 0.7261 - val_loss: 0.8304 - val_accuracy: 0.6495\n",
      "Epoch 30/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6795 - accuracy: 0.7217 - val_loss: 0.7085 - val_accuracy: 0.6887\n",
      "Epoch 31/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6758 - accuracy: 0.7300 - val_loss: 0.8245 - val_accuracy: 0.6394\n",
      "Epoch 32/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6721 - accuracy: 0.7327 - val_loss: 0.8252 - val_accuracy: 0.6338\n",
      "Epoch 33/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6631 - accuracy: 0.7239 - val_loss: 0.7578 - val_accuracy: 0.6842\n",
      "Epoch 34/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6604 - accuracy: 0.7294 - val_loss: 0.7250 - val_accuracy: 0.6786\n",
      "Epoch 35/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6527 - accuracy: 0.7350 - val_loss: 0.7992 - val_accuracy: 0.6540\n",
      "Epoch 36/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6492 - accuracy: 0.7350 - val_loss: 0.6721 - val_accuracy: 0.7245\n",
      "Epoch 37/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6469 - accuracy: 0.7261 - val_loss: 0.7131 - val_accuracy: 0.6887\n",
      "Epoch 38/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6430 - accuracy: 0.7388 - val_loss: 0.6997 - val_accuracy: 0.7010\n",
      "Epoch 39/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6460 - accuracy: 0.7333 - val_loss: 0.6846 - val_accuracy: 0.7055\n",
      "Epoch 40/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6342 - accuracy: 0.7493 - val_loss: 0.7100 - val_accuracy: 0.6876\n",
      "Epoch 41/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6345 - accuracy: 0.7377 - val_loss: 0.6784 - val_accuracy: 0.7111\n",
      "Epoch 42/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6275 - accuracy: 0.7532 - val_loss: 0.7023 - val_accuracy: 0.6943\n",
      "Epoch 43/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6242 - accuracy: 0.7493 - val_loss: 0.7247 - val_accuracy: 0.6697\n",
      "Epoch 44/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6239 - accuracy: 0.7410 - val_loss: 0.7517 - val_accuracy: 0.6652\n",
      "Epoch 45/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6265 - accuracy: 0.7526 - val_loss: 0.7243 - val_accuracy: 0.6943\n",
      "Epoch 46/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6215 - accuracy: 0.7581 - val_loss: 0.6755 - val_accuracy: 0.7133\n",
      "Epoch 47/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6101 - accuracy: 0.7570 - val_loss: 0.7674 - val_accuracy: 0.6461\n",
      "Epoch 48/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6105 - accuracy: 0.7510 - val_loss: 0.6835 - val_accuracy: 0.7100\n",
      "Epoch 49/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6029 - accuracy: 0.7592 - val_loss: 0.6186 - val_accuracy: 0.7536\n",
      "Epoch 50/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6041 - accuracy: 0.7576 - val_loss: 0.6711 - val_accuracy: 0.7111\n",
      "Epoch 51/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.6000 - accuracy: 0.7499 - val_loss: 0.6379 - val_accuracy: 0.7458\n",
      "Epoch 52/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5925 - accuracy: 0.7659 - val_loss: 0.7321 - val_accuracy: 0.6708\n",
      "Epoch 53/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5954 - accuracy: 0.7609 - val_loss: 0.7213 - val_accuracy: 0.6988\n",
      "Epoch 54/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5927 - accuracy: 0.7692 - val_loss: 0.6387 - val_accuracy: 0.7436\n",
      "Epoch 55/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5906 - accuracy: 0.7686 - val_loss: 0.6358 - val_accuracy: 0.7245\n",
      "Epoch 56/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5866 - accuracy: 0.7631 - val_loss: 0.6405 - val_accuracy: 0.7256\n",
      "Epoch 57/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5841 - accuracy: 0.7659 - val_loss: 0.6104 - val_accuracy: 0.7626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5824 - accuracy: 0.7753 - val_loss: 0.6354 - val_accuracy: 0.7346\n",
      "Epoch 59/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5820 - accuracy: 0.7736 - val_loss: 0.6402 - val_accuracy: 0.7178\n",
      "Epoch 60/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5777 - accuracy: 0.7708 - val_loss: 0.7407 - val_accuracy: 0.6775\n",
      "Epoch 61/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5762 - accuracy: 0.7703 - val_loss: 0.5888 - val_accuracy: 0.7749\n",
      "Epoch 62/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5746 - accuracy: 0.7758 - val_loss: 0.7091 - val_accuracy: 0.7021\n",
      "Epoch 63/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5724 - accuracy: 0.7758 - val_loss: 0.6429 - val_accuracy: 0.7380\n",
      "Epoch 64/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5665 - accuracy: 0.7808 - val_loss: 0.6054 - val_accuracy: 0.7604\n",
      "Epoch 65/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5680 - accuracy: 0.7918 - val_loss: 0.6420 - val_accuracy: 0.7178\n",
      "Epoch 66/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5667 - accuracy: 0.7703 - val_loss: 0.6133 - val_accuracy: 0.7581\n",
      "Epoch 67/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5602 - accuracy: 0.7880 - val_loss: 0.5800 - val_accuracy: 0.7861\n",
      "Epoch 68/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5624 - accuracy: 0.7819 - val_loss: 0.6073 - val_accuracy: 0.7626\n",
      "Epoch 69/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5634 - accuracy: 0.7797 - val_loss: 0.5841 - val_accuracy: 0.7772\n",
      "Epoch 70/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5533 - accuracy: 0.7819 - val_loss: 0.6716 - val_accuracy: 0.7077\n",
      "Epoch 71/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5566 - accuracy: 0.7902 - val_loss: 0.6455 - val_accuracy: 0.7503\n",
      "Epoch 72/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5515 - accuracy: 0.7830 - val_loss: 0.6187 - val_accuracy: 0.7380\n",
      "Epoch 73/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5525 - accuracy: 0.7863 - val_loss: 0.5916 - val_accuracy: 0.7559\n",
      "Epoch 74/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5461 - accuracy: 0.7918 - val_loss: 0.5757 - val_accuracy: 0.7850\n",
      "Epoch 75/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5394 - accuracy: 0.7968 - val_loss: 0.6375 - val_accuracy: 0.7492\n",
      "Epoch 76/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5469 - accuracy: 0.7880 - val_loss: 0.5662 - val_accuracy: 0.7794\n",
      "Epoch 77/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5388 - accuracy: 0.7951 - val_loss: 0.5958 - val_accuracy: 0.7480\n",
      "Epoch 78/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5463 - accuracy: 0.7940 - val_loss: 0.5607 - val_accuracy: 0.7962\n",
      "Epoch 79/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5450 - accuracy: 0.7885 - val_loss: 0.5816 - val_accuracy: 0.7772\n",
      "Epoch 80/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5360 - accuracy: 0.7891 - val_loss: 0.5646 - val_accuracy: 0.7816\n",
      "Epoch 81/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5372 - accuracy: 0.7913 - val_loss: 0.6138 - val_accuracy: 0.7503\n",
      "Epoch 82/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5337 - accuracy: 0.7985 - val_loss: 0.6420 - val_accuracy: 0.7234\n",
      "Epoch 83/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5328 - accuracy: 0.7996 - val_loss: 0.5848 - val_accuracy: 0.7626\n",
      "Epoch 84/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5247 - accuracy: 0.7962 - val_loss: 0.5601 - val_accuracy: 0.7805\n",
      "Epoch 85/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5273 - accuracy: 0.7935 - val_loss: 0.5660 - val_accuracy: 0.7592\n",
      "Epoch 86/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5239 - accuracy: 0.7957 - val_loss: 0.5954 - val_accuracy: 0.7648\n",
      "Epoch 87/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5236 - accuracy: 0.7929 - val_loss: 0.6071 - val_accuracy: 0.7458\n",
      "Epoch 88/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5240 - accuracy: 0.7918 - val_loss: 0.5560 - val_accuracy: 0.7884\n",
      "Epoch 89/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5214 - accuracy: 0.7946 - val_loss: 0.6082 - val_accuracy: 0.7223\n",
      "Epoch 90/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5186 - accuracy: 0.8001 - val_loss: 0.5647 - val_accuracy: 0.7828\n",
      "Epoch 91/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5215 - accuracy: 0.8034 - val_loss: 0.5559 - val_accuracy: 0.7940\n",
      "Epoch 92/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5193 - accuracy: 0.7929 - val_loss: 0.5377 - val_accuracy: 0.8040\n",
      "Epoch 93/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5155 - accuracy: 0.8183 - val_loss: 0.5563 - val_accuracy: 0.7637\n",
      "Epoch 94/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5140 - accuracy: 0.8100 - val_loss: 0.5876 - val_accuracy: 0.7436\n",
      "Epoch 95/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5122 - accuracy: 0.8062 - val_loss: 0.5578 - val_accuracy: 0.7716\n",
      "Epoch 96/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5110 - accuracy: 0.8100 - val_loss: 0.5933 - val_accuracy: 0.7615\n",
      "Epoch 97/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5123 - accuracy: 0.8056 - val_loss: 0.5485 - val_accuracy: 0.8007\n",
      "Epoch 98/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5040 - accuracy: 0.8139 - val_loss: 0.5465 - val_accuracy: 0.7805\n",
      "Epoch 99/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5015 - accuracy: 0.8012 - val_loss: 0.5261 - val_accuracy: 0.8063\n",
      "Epoch 100/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5001 - accuracy: 0.8023 - val_loss: 0.5769 - val_accuracy: 0.7581\n",
      "Epoch 101/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5026 - accuracy: 0.8018 - val_loss: 0.5374 - val_accuracy: 0.8063\n",
      "Epoch 102/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4980 - accuracy: 0.8056 - val_loss: 0.5456 - val_accuracy: 0.7727\n",
      "Epoch 103/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5050 - accuracy: 0.8029 - val_loss: 0.5987 - val_accuracy: 0.7245\n",
      "Epoch 104/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.5003 - accuracy: 0.8117 - val_loss: 0.5389 - val_accuracy: 0.7727\n",
      "Epoch 105/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4922 - accuracy: 0.8089 - val_loss: 0.6047 - val_accuracy: 0.7559\n",
      "Epoch 106/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4917 - accuracy: 0.8200 - val_loss: 0.6246 - val_accuracy: 0.7111\n",
      "Epoch 107/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4996 - accuracy: 0.8029 - val_loss: 0.5906 - val_accuracy: 0.7648\n",
      "Epoch 108/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4906 - accuracy: 0.8178 - val_loss: 0.5974 - val_accuracy: 0.7324\n",
      "Epoch 109/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4918 - accuracy: 0.8189 - val_loss: 0.5316 - val_accuracy: 0.8007\n",
      "Epoch 110/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4936 - accuracy: 0.8183 - val_loss: 0.5549 - val_accuracy: 0.7648\n",
      "Epoch 111/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4911 - accuracy: 0.8216 - val_loss: 0.5550 - val_accuracy: 0.7772\n",
      "Epoch 112/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4905 - accuracy: 0.8128 - val_loss: 0.5185 - val_accuracy: 0.7940\n",
      "Epoch 113/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4855 - accuracy: 0.8117 - val_loss: 0.5362 - val_accuracy: 0.7839\n",
      "Epoch 114/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4870 - accuracy: 0.8150 - val_loss: 0.5337 - val_accuracy: 0.7996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4874 - accuracy: 0.8200 - val_loss: 0.5948 - val_accuracy: 0.7492\n",
      "Epoch 116/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4853 - accuracy: 0.8156 - val_loss: 0.5936 - val_accuracy: 0.7436\n",
      "Epoch 117/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4832 - accuracy: 0.8167 - val_loss: 0.5180 - val_accuracy: 0.8186\n",
      "Epoch 118/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4842 - accuracy: 0.8183 - val_loss: 0.5044 - val_accuracy: 0.8119\n",
      "Epoch 119/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4827 - accuracy: 0.8123 - val_loss: 0.5533 - val_accuracy: 0.7581\n",
      "Epoch 120/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4756 - accuracy: 0.8167 - val_loss: 0.5027 - val_accuracy: 0.8242\n",
      "Epoch 121/500\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.4752 - accuracy: 0.8255 - val_loss: 0.5521 - val_accuracy: 0.7480\n",
      "Epoch 122/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4759 - accuracy: 0.8200 - val_loss: 0.5483 - val_accuracy: 0.7615\n",
      "Epoch 123/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4738 - accuracy: 0.8222 - val_loss: 0.5150 - val_accuracy: 0.8141\n",
      "Epoch 124/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4759 - accuracy: 0.8266 - val_loss: 0.4978 - val_accuracy: 0.8063\n",
      "Epoch 125/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4730 - accuracy: 0.8266 - val_loss: 0.5166 - val_accuracy: 0.7839\n",
      "Epoch 126/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4737 - accuracy: 0.8244 - val_loss: 0.5151 - val_accuracy: 0.7760\n",
      "Epoch 127/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4685 - accuracy: 0.8227 - val_loss: 0.5161 - val_accuracy: 0.7906\n",
      "Epoch 128/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4688 - accuracy: 0.8205 - val_loss: 0.6554 - val_accuracy: 0.7234\n",
      "Epoch 129/500\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.4702 - accuracy: 0.8332 - val_loss: 0.5034 - val_accuracy: 0.8130\n",
      "Epoch 130/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4711 - accuracy: 0.8167 - val_loss: 0.4897 - val_accuracy: 0.8163\n",
      "Epoch 131/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4688 - accuracy: 0.8205 - val_loss: 0.5424 - val_accuracy: 0.7716\n",
      "Epoch 132/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4669 - accuracy: 0.8233 - val_loss: 0.4835 - val_accuracy: 0.8309\n",
      "Epoch 133/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4659 - accuracy: 0.8277 - val_loss: 0.5594 - val_accuracy: 0.7738\n",
      "Epoch 134/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4655 - accuracy: 0.8255 - val_loss: 0.5085 - val_accuracy: 0.8197\n",
      "Epoch 135/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4654 - accuracy: 0.8360 - val_loss: 0.5242 - val_accuracy: 0.7984\n",
      "Epoch 136/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4627 - accuracy: 0.8250 - val_loss: 0.5611 - val_accuracy: 0.7794\n",
      "Epoch 137/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4594 - accuracy: 0.8272 - val_loss: 0.5374 - val_accuracy: 0.7895\n",
      "Epoch 138/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4595 - accuracy: 0.8371 - val_loss: 0.6045 - val_accuracy: 0.7480\n",
      "Epoch 139/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4606 - accuracy: 0.8250 - val_loss: 0.4916 - val_accuracy: 0.8175\n",
      "Epoch 140/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4597 - accuracy: 0.8288 - val_loss: 0.5670 - val_accuracy: 0.7447\n",
      "Epoch 141/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4568 - accuracy: 0.8332 - val_loss: 0.4992 - val_accuracy: 0.8197\n",
      "Epoch 142/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4573 - accuracy: 0.8321 - val_loss: 0.5039 - val_accuracy: 0.7996\n",
      "Epoch 143/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4521 - accuracy: 0.8459 - val_loss: 0.4929 - val_accuracy: 0.8108\n",
      "Epoch 144/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4573 - accuracy: 0.8305 - val_loss: 0.4888 - val_accuracy: 0.8175\n",
      "Epoch 145/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4560 - accuracy: 0.8233 - val_loss: 0.4924 - val_accuracy: 0.8141\n",
      "Epoch 146/500\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 0.4465 - accuracy: 0.8332 - val_loss: 0.5243 - val_accuracy: 0.8130\n",
      "Epoch 147/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4518 - accuracy: 0.8277 - val_loss: 0.4921 - val_accuracy: 0.8197\n",
      "Epoch 148/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4488 - accuracy: 0.8305 - val_loss: 0.4879 - val_accuracy: 0.8163\n",
      "Epoch 149/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4456 - accuracy: 0.8371 - val_loss: 0.5078 - val_accuracy: 0.7805\n",
      "Epoch 150/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4492 - accuracy: 0.8343 - val_loss: 0.5345 - val_accuracy: 0.7906\n",
      "Epoch 151/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4452 - accuracy: 0.8310 - val_loss: 0.5093 - val_accuracy: 0.7917\n",
      "Epoch 152/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4466 - accuracy: 0.8366 - val_loss: 0.4960 - val_accuracy: 0.8208\n",
      "Epoch 153/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4418 - accuracy: 0.8310 - val_loss: 0.5268 - val_accuracy: 0.7951\n",
      "Epoch 154/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4418 - accuracy: 0.8343 - val_loss: 0.4803 - val_accuracy: 0.8197\n",
      "Epoch 155/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4383 - accuracy: 0.8426 - val_loss: 0.5050 - val_accuracy: 0.8018\n",
      "Epoch 156/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4396 - accuracy: 0.8371 - val_loss: 0.4820 - val_accuracy: 0.8231\n",
      "Epoch 157/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4442 - accuracy: 0.8371 - val_loss: 0.4822 - val_accuracy: 0.8208\n",
      "Epoch 158/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4401 - accuracy: 0.8476 - val_loss: 0.4807 - val_accuracy: 0.8163\n",
      "Epoch 159/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4349 - accuracy: 0.8437 - val_loss: 0.5196 - val_accuracy: 0.7783\n",
      "Epoch 160/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4389 - accuracy: 0.8371 - val_loss: 0.4717 - val_accuracy: 0.8287\n",
      "Epoch 161/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4391 - accuracy: 0.8327 - val_loss: 0.4742 - val_accuracy: 0.8219\n",
      "Epoch 162/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4324 - accuracy: 0.8432 - val_loss: 0.5015 - val_accuracy: 0.8152\n",
      "Epoch 163/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4335 - accuracy: 0.8371 - val_loss: 0.4854 - val_accuracy: 0.7928\n",
      "Epoch 164/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4362 - accuracy: 0.8504 - val_loss: 0.5063 - val_accuracy: 0.7772\n",
      "Epoch 165/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4312 - accuracy: 0.8410 - val_loss: 0.4805 - val_accuracy: 0.8163\n",
      "Epoch 166/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4326 - accuracy: 0.8393 - val_loss: 0.4561 - val_accuracy: 0.8376\n",
      "Epoch 167/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4300 - accuracy: 0.8437 - val_loss: 0.5335 - val_accuracy: 0.7962\n",
      "Epoch 168/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4332 - accuracy: 0.8459 - val_loss: 0.4779 - val_accuracy: 0.8309\n",
      "Epoch 169/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4279 - accuracy: 0.8404 - val_loss: 0.4639 - val_accuracy: 0.8410\n",
      "Epoch 170/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4299 - accuracy: 0.8487 - val_loss: 0.4994 - val_accuracy: 0.7884\n",
      "Epoch 171/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4308 - accuracy: 0.8454 - val_loss: 0.4876 - val_accuracy: 0.7973\n",
      "Epoch 172/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4277 - accuracy: 0.8437 - val_loss: 0.5020 - val_accuracy: 0.7861\n",
      "Epoch 173/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4266 - accuracy: 0.8537 - val_loss: 0.5227 - val_accuracy: 0.7682\n",
      "Epoch 174/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4293 - accuracy: 0.8377 - val_loss: 0.5549 - val_accuracy: 0.7693\n",
      "Epoch 175/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4255 - accuracy: 0.8459 - val_loss: 0.4534 - val_accuracy: 0.8432\n",
      "Epoch 176/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4222 - accuracy: 0.8388 - val_loss: 0.5209 - val_accuracy: 0.7928\n",
      "Epoch 177/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4207 - accuracy: 0.8482 - val_loss: 0.5100 - val_accuracy: 0.8018\n",
      "Epoch 178/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4195 - accuracy: 0.8493 - val_loss: 0.5745 - val_accuracy: 0.7749\n",
      "Epoch 179/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4240 - accuracy: 0.8415 - val_loss: 0.5728 - val_accuracy: 0.7749\n",
      "Epoch 180/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4237 - accuracy: 0.8454 - val_loss: 0.4801 - val_accuracy: 0.8320\n",
      "Epoch 181/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4209 - accuracy: 0.8448 - val_loss: 0.4745 - val_accuracy: 0.8007\n",
      "Epoch 182/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4213 - accuracy: 0.8498 - val_loss: 0.4428 - val_accuracy: 0.8421\n",
      "Epoch 183/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4144 - accuracy: 0.8476 - val_loss: 0.5028 - val_accuracy: 0.8096\n",
      "Epoch 184/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4168 - accuracy: 0.8498 - val_loss: 0.4559 - val_accuracy: 0.8410\n",
      "Epoch 185/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4157 - accuracy: 0.8382 - val_loss: 0.4946 - val_accuracy: 0.8253\n",
      "Epoch 186/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4166 - accuracy: 0.8476 - val_loss: 0.4905 - val_accuracy: 0.8096\n",
      "Epoch 187/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4185 - accuracy: 0.8537 - val_loss: 0.5494 - val_accuracy: 0.7805\n",
      "Epoch 188/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4181 - accuracy: 0.8459 - val_loss: 0.4889 - val_accuracy: 0.8130\n",
      "Epoch 189/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4094 - accuracy: 0.8437 - val_loss: 0.5958 - val_accuracy: 0.7503\n",
      "Epoch 190/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4191 - accuracy: 0.8454 - val_loss: 0.4850 - val_accuracy: 0.8108\n",
      "Epoch 191/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4141 - accuracy: 0.8531 - val_loss: 0.5278 - val_accuracy: 0.7816\n",
      "Epoch 192/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4114 - accuracy: 0.8520 - val_loss: 0.4757 - val_accuracy: 0.8231\n",
      "Epoch 193/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4093 - accuracy: 0.8531 - val_loss: 0.4819 - val_accuracy: 0.8040\n",
      "Epoch 194/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4107 - accuracy: 0.8465 - val_loss: 0.4577 - val_accuracy: 0.8253\n",
      "Epoch 195/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4095 - accuracy: 0.8553 - val_loss: 0.5062 - val_accuracy: 0.7951\n",
      "Epoch 196/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4094 - accuracy: 0.8537 - val_loss: 0.5446 - val_accuracy: 0.7760\n",
      "Epoch 197/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4066 - accuracy: 0.8537 - val_loss: 0.4515 - val_accuracy: 0.8197\n",
      "Epoch 198/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4113 - accuracy: 0.8459 - val_loss: 0.4609 - val_accuracy: 0.8108\n",
      "Epoch 199/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4056 - accuracy: 0.8553 - val_loss: 0.4627 - val_accuracy: 0.8376\n",
      "Epoch 200/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4005 - accuracy: 0.8443 - val_loss: 0.4856 - val_accuracy: 0.8096\n",
      "Epoch 201/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4073 - accuracy: 0.8559 - val_loss: 0.4423 - val_accuracy: 0.8522\n",
      "Epoch 202/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4070 - accuracy: 0.8493 - val_loss: 0.4689 - val_accuracy: 0.8108\n",
      "Epoch 203/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3987 - accuracy: 0.8548 - val_loss: 0.5574 - val_accuracy: 0.7738\n",
      "Epoch 204/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4099 - accuracy: 0.8498 - val_loss: 0.4593 - val_accuracy: 0.8052\n",
      "Epoch 205/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4066 - accuracy: 0.8570 - val_loss: 0.4511 - val_accuracy: 0.8522\n",
      "Epoch 206/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4005 - accuracy: 0.8493 - val_loss: 0.4913 - val_accuracy: 0.7749\n",
      "Epoch 207/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4032 - accuracy: 0.8476 - val_loss: 0.4954 - val_accuracy: 0.8040\n",
      "Epoch 208/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4060 - accuracy: 0.8432 - val_loss: 0.4267 - val_accuracy: 0.8466\n",
      "Epoch 209/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.4002 - accuracy: 0.8553 - val_loss: 0.4348 - val_accuracy: 0.8555\n",
      "Epoch 210/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3993 - accuracy: 0.8542 - val_loss: 0.5261 - val_accuracy: 0.7559\n",
      "Epoch 211/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3970 - accuracy: 0.8542 - val_loss: 0.4747 - val_accuracy: 0.8275\n",
      "Epoch 212/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3949 - accuracy: 0.8597 - val_loss: 0.4638 - val_accuracy: 0.8242\n",
      "Epoch 213/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3918 - accuracy: 0.8625 - val_loss: 0.5030 - val_accuracy: 0.7962\n",
      "Epoch 214/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3992 - accuracy: 0.8603 - val_loss: 0.4479 - val_accuracy: 0.8242\n",
      "Epoch 215/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3968 - accuracy: 0.8504 - val_loss: 0.4365 - val_accuracy: 0.8499\n",
      "Epoch 216/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3947 - accuracy: 0.8559 - val_loss: 0.4922 - val_accuracy: 0.7816\n",
      "Epoch 217/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3946 - accuracy: 0.8526 - val_loss: 0.4541 - val_accuracy: 0.8309\n",
      "Epoch 218/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3930 - accuracy: 0.8520 - val_loss: 0.4318 - val_accuracy: 0.8399\n",
      "Epoch 219/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3948 - accuracy: 0.8609 - val_loss: 0.4275 - val_accuracy: 0.8443\n",
      "Epoch 220/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3932 - accuracy: 0.8609 - val_loss: 0.4668 - val_accuracy: 0.8108\n",
      "Epoch 221/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3945 - accuracy: 0.8498 - val_loss: 0.4300 - val_accuracy: 0.8455\n",
      "Epoch 222/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3896 - accuracy: 0.8564 - val_loss: 0.4435 - val_accuracy: 0.8275\n",
      "Epoch 223/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3921 - accuracy: 0.8603 - val_loss: 0.4274 - val_accuracy: 0.8488\n",
      "Epoch 224/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3891 - accuracy: 0.8680 - val_loss: 0.4425 - val_accuracy: 0.8399\n",
      "Epoch 225/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3910 - accuracy: 0.8548 - val_loss: 0.5276 - val_accuracy: 0.7716\n",
      "Epoch 226/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3916 - accuracy: 0.8581 - val_loss: 0.5086 - val_accuracy: 0.7984\n",
      "Epoch 227/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3897 - accuracy: 0.8542 - val_loss: 0.4504 - val_accuracy: 0.8387\n",
      "Epoch 228/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3860 - accuracy: 0.8614 - val_loss: 0.4698 - val_accuracy: 0.8253\n",
      "Epoch 229/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3895 - accuracy: 0.8592 - val_loss: 0.4266 - val_accuracy: 0.8477\n",
      "Epoch 230/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3833 - accuracy: 0.8691 - val_loss: 0.5036 - val_accuracy: 0.7928\n",
      "Epoch 231/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3853 - accuracy: 0.8625 - val_loss: 0.4326 - val_accuracy: 0.8511\n",
      "Epoch 232/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3874 - accuracy: 0.8597 - val_loss: 0.4555 - val_accuracy: 0.8175\n",
      "Epoch 233/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3860 - accuracy: 0.8708 - val_loss: 0.4724 - val_accuracy: 0.7839\n",
      "Epoch 234/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3819 - accuracy: 0.8592 - val_loss: 0.4317 - val_accuracy: 0.8443\n",
      "Epoch 235/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3822 - accuracy: 0.8675 - val_loss: 0.4560 - val_accuracy: 0.8309\n",
      "Epoch 236/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3803 - accuracy: 0.8680 - val_loss: 0.4265 - val_accuracy: 0.8320\n",
      "Epoch 237/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3812 - accuracy: 0.8614 - val_loss: 0.4374 - val_accuracy: 0.8287\n",
      "Epoch 238/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3819 - accuracy: 0.8592 - val_loss: 0.5191 - val_accuracy: 0.7760\n",
      "Epoch 239/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3840 - accuracy: 0.8537 - val_loss: 0.4329 - val_accuracy: 0.8275\n",
      "Epoch 240/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3811 - accuracy: 0.8631 - val_loss: 0.4920 - val_accuracy: 0.8040\n",
      "Epoch 241/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3808 - accuracy: 0.8620 - val_loss: 0.4197 - val_accuracy: 0.8399\n",
      "Epoch 242/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3797 - accuracy: 0.8570 - val_loss: 0.4210 - val_accuracy: 0.8499\n",
      "Epoch 243/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3807 - accuracy: 0.8620 - val_loss: 0.4210 - val_accuracy: 0.8466\n",
      "Epoch 244/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3777 - accuracy: 0.8647 - val_loss: 0.4295 - val_accuracy: 0.8376\n",
      "Epoch 245/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3786 - accuracy: 0.8636 - val_loss: 0.4621 - val_accuracy: 0.8197\n",
      "Epoch 246/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3760 - accuracy: 0.8691 - val_loss: 0.4541 - val_accuracy: 0.8007\n",
      "Epoch 247/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3771 - accuracy: 0.8691 - val_loss: 0.5136 - val_accuracy: 0.7917\n",
      "Epoch 248/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3743 - accuracy: 0.8548 - val_loss: 0.4192 - val_accuracy: 0.8410\n",
      "Epoch 249/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3742 - accuracy: 0.8597 - val_loss: 0.4371 - val_accuracy: 0.8208\n",
      "Epoch 250/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3753 - accuracy: 0.8570 - val_loss: 0.4259 - val_accuracy: 0.8511\n",
      "Epoch 251/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3727 - accuracy: 0.8669 - val_loss: 0.4482 - val_accuracy: 0.8219\n",
      "Epoch 252/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3768 - accuracy: 0.8631 - val_loss: 0.4490 - val_accuracy: 0.8141\n",
      "Epoch 253/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3744 - accuracy: 0.8675 - val_loss: 0.4350 - val_accuracy: 0.8208\n",
      "Epoch 254/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3736 - accuracy: 0.8647 - val_loss: 0.4418 - val_accuracy: 0.8287\n",
      "Epoch 255/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3685 - accuracy: 0.8680 - val_loss: 0.4151 - val_accuracy: 0.8443\n",
      "Epoch 256/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3757 - accuracy: 0.8642 - val_loss: 0.4168 - val_accuracy: 0.8589\n",
      "Epoch 257/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3759 - accuracy: 0.8581 - val_loss: 0.4133 - val_accuracy: 0.8555\n",
      "Epoch 258/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3712 - accuracy: 0.8625 - val_loss: 0.4285 - val_accuracy: 0.8477\n",
      "Epoch 259/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3677 - accuracy: 0.8675 - val_loss: 0.4132 - val_accuracy: 0.8477\n",
      "Epoch 260/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3676 - accuracy: 0.8625 - val_loss: 0.4242 - val_accuracy: 0.8432\n",
      "Epoch 261/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3691 - accuracy: 0.8564 - val_loss: 0.4610 - val_accuracy: 0.8052\n",
      "Epoch 262/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3691 - accuracy: 0.8680 - val_loss: 0.4091 - val_accuracy: 0.8466\n",
      "Epoch 263/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3622 - accuracy: 0.8697 - val_loss: 0.4764 - val_accuracy: 0.8108\n",
      "Epoch 264/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3674 - accuracy: 0.8713 - val_loss: 0.4618 - val_accuracy: 0.8320\n",
      "Epoch 265/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3695 - accuracy: 0.8653 - val_loss: 0.4607 - val_accuracy: 0.8343\n",
      "Epoch 266/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3641 - accuracy: 0.8758 - val_loss: 0.4201 - val_accuracy: 0.8399\n",
      "Epoch 267/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3675 - accuracy: 0.8680 - val_loss: 0.4284 - val_accuracy: 0.8477\n",
      "Epoch 268/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3651 - accuracy: 0.8658 - val_loss: 0.4043 - val_accuracy: 0.8533\n",
      "Epoch 269/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3580 - accuracy: 0.8697 - val_loss: 0.4637 - val_accuracy: 0.7996\n",
      "Epoch 270/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3643 - accuracy: 0.8625 - val_loss: 0.6234 - val_accuracy: 0.7548\n",
      "Epoch 271/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3661 - accuracy: 0.8675 - val_loss: 0.4635 - val_accuracy: 0.8231\n",
      "Epoch 272/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3652 - accuracy: 0.8686 - val_loss: 0.4365 - val_accuracy: 0.8231\n",
      "Epoch 273/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3599 - accuracy: 0.8653 - val_loss: 0.4108 - val_accuracy: 0.8544\n",
      "Epoch 274/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3612 - accuracy: 0.8686 - val_loss: 0.4277 - val_accuracy: 0.8298\n",
      "Epoch 275/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3591 - accuracy: 0.8763 - val_loss: 0.4254 - val_accuracy: 0.8242\n",
      "Epoch 276/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3566 - accuracy: 0.8730 - val_loss: 0.4173 - val_accuracy: 0.8354\n",
      "Epoch 277/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3555 - accuracy: 0.8763 - val_loss: 0.4582 - val_accuracy: 0.8343\n",
      "Epoch 278/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3629 - accuracy: 0.8752 - val_loss: 0.4451 - val_accuracy: 0.8253\n",
      "Epoch 279/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3595 - accuracy: 0.8702 - val_loss: 0.4190 - val_accuracy: 0.8421\n",
      "Epoch 280/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3613 - accuracy: 0.8724 - val_loss: 0.4586 - val_accuracy: 0.8387\n",
      "Epoch 281/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3591 - accuracy: 0.8669 - val_loss: 0.4723 - val_accuracy: 0.8063\n",
      "Epoch 282/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3582 - accuracy: 0.8675 - val_loss: 0.4505 - val_accuracy: 0.8242\n",
      "Epoch 283/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3564 - accuracy: 0.8758 - val_loss: 0.4038 - val_accuracy: 0.8522\n",
      "Epoch 284/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3535 - accuracy: 0.8807 - val_loss: 0.4803 - val_accuracy: 0.8108\n",
      "Epoch 285/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3580 - accuracy: 0.8702 - val_loss: 0.4086 - val_accuracy: 0.8399\n",
      "Epoch 286/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3541 - accuracy: 0.8741 - val_loss: 0.4331 - val_accuracy: 0.8219\n",
      "Epoch 287/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3542 - accuracy: 0.8807 - val_loss: 0.4462 - val_accuracy: 0.8343\n",
      "Epoch 288/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3539 - accuracy: 0.8636 - val_loss: 0.4708 - val_accuracy: 0.8052\n",
      "Epoch 289/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3540 - accuracy: 0.8658 - val_loss: 0.4738 - val_accuracy: 0.7940\n",
      "Epoch 290/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3538 - accuracy: 0.8730 - val_loss: 0.4145 - val_accuracy: 0.8488\n",
      "Epoch 291/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3538 - accuracy: 0.8708 - val_loss: 0.4125 - val_accuracy: 0.8399\n",
      "Epoch 292/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3533 - accuracy: 0.8741 - val_loss: 0.3912 - val_accuracy: 0.8634\n",
      "Epoch 293/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3528 - accuracy: 0.8747 - val_loss: 0.4012 - val_accuracy: 0.8443\n",
      "Epoch 294/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3552 - accuracy: 0.8680 - val_loss: 0.4125 - val_accuracy: 0.8488\n",
      "Epoch 295/500\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.3524 - accuracy: 0.8669 - val_loss: 0.4018 - val_accuracy: 0.8611\n",
      "Epoch 296/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3481 - accuracy: 0.8780 - val_loss: 0.3966 - val_accuracy: 0.8443\n",
      "Epoch 297/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3506 - accuracy: 0.8724 - val_loss: 0.4063 - val_accuracy: 0.8544\n",
      "Epoch 298/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3514 - accuracy: 0.8736 - val_loss: 0.4191 - val_accuracy: 0.8331\n",
      "Epoch 299/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3488 - accuracy: 0.8702 - val_loss: 0.4056 - val_accuracy: 0.8611\n",
      "Epoch 300/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3486 - accuracy: 0.8835 - val_loss: 0.3886 - val_accuracy: 0.8544\n",
      "Epoch 301/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3450 - accuracy: 0.8774 - val_loss: 0.4109 - val_accuracy: 0.8499\n",
      "Epoch 302/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3439 - accuracy: 0.8724 - val_loss: 0.4034 - val_accuracy: 0.8623\n",
      "Epoch 303/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3486 - accuracy: 0.8719 - val_loss: 0.4278 - val_accuracy: 0.8287\n",
      "Epoch 304/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3481 - accuracy: 0.8785 - val_loss: 0.4090 - val_accuracy: 0.8455\n",
      "Epoch 305/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3469 - accuracy: 0.8769 - val_loss: 0.3906 - val_accuracy: 0.8645\n",
      "Epoch 306/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3444 - accuracy: 0.8763 - val_loss: 0.4478 - val_accuracy: 0.8399\n",
      "Epoch 307/500\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.3482 - accuracy: 0.8747 - val_loss: 0.4215 - val_accuracy: 0.8298\n",
      "Epoch 308/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3421 - accuracy: 0.8813 - val_loss: 0.4414 - val_accuracy: 0.8264\n",
      "Epoch 309/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3463 - accuracy: 0.8752 - val_loss: 0.4084 - val_accuracy: 0.8466\n",
      "Epoch 310/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3491 - accuracy: 0.8741 - val_loss: 0.3967 - val_accuracy: 0.8567\n",
      "Epoch 311/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3437 - accuracy: 0.8752 - val_loss: 0.3979 - val_accuracy: 0.8432\n",
      "Epoch 312/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3403 - accuracy: 0.8769 - val_loss: 0.4467 - val_accuracy: 0.8141\n",
      "Epoch 313/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3440 - accuracy: 0.8758 - val_loss: 0.4008 - val_accuracy: 0.8589\n",
      "Epoch 314/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3442 - accuracy: 0.8708 - val_loss: 0.4166 - val_accuracy: 0.8522\n",
      "Epoch 315/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3387 - accuracy: 0.8829 - val_loss: 0.4240 - val_accuracy: 0.8410\n",
      "Epoch 316/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3406 - accuracy: 0.8747 - val_loss: 0.4269 - val_accuracy: 0.8298\n",
      "Epoch 317/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3413 - accuracy: 0.8774 - val_loss: 0.3903 - val_accuracy: 0.8499\n",
      "Epoch 318/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3384 - accuracy: 0.8835 - val_loss: 0.4001 - val_accuracy: 0.8443\n",
      "Epoch 319/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3420 - accuracy: 0.8824 - val_loss: 0.4175 - val_accuracy: 0.8432\n",
      "Epoch 320/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3430 - accuracy: 0.8769 - val_loss: 0.4067 - val_accuracy: 0.8343\n",
      "Epoch 321/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3379 - accuracy: 0.8758 - val_loss: 0.4156 - val_accuracy: 0.8499\n",
      "Epoch 322/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3384 - accuracy: 0.8752 - val_loss: 0.4361 - val_accuracy: 0.8287\n",
      "Epoch 323/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3336 - accuracy: 0.8890 - val_loss: 0.3908 - val_accuracy: 0.8634\n",
      "Epoch 324/500\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 0.3410 - accuracy: 0.8818 - val_loss: 0.3916 - val_accuracy: 0.8522\n",
      "Epoch 325/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3352 - accuracy: 0.8807 - val_loss: 0.4615 - val_accuracy: 0.8175\n",
      "Epoch 326/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3371 - accuracy: 0.8691 - val_loss: 0.3956 - val_accuracy: 0.8466\n",
      "Epoch 327/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3300 - accuracy: 0.8846 - val_loss: 0.3831 - val_accuracy: 0.8522\n",
      "Epoch 328/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3366 - accuracy: 0.8758 - val_loss: 0.4490 - val_accuracy: 0.8074\n",
      "Epoch 329/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3349 - accuracy: 0.8774 - val_loss: 0.4138 - val_accuracy: 0.8399\n",
      "Epoch 330/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3314 - accuracy: 0.8824 - val_loss: 0.4123 - val_accuracy: 0.8511\n",
      "Epoch 331/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3379 - accuracy: 0.8741 - val_loss: 0.4280 - val_accuracy: 0.8376\n",
      "Epoch 332/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3355 - accuracy: 0.8691 - val_loss: 0.4195 - val_accuracy: 0.8275\n",
      "Epoch 333/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3318 - accuracy: 0.8769 - val_loss: 0.3932 - val_accuracy: 0.8466\n",
      "Epoch 334/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3309 - accuracy: 0.8824 - val_loss: 0.3941 - val_accuracy: 0.8544\n",
      "Epoch 335/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3329 - accuracy: 0.8769 - val_loss: 0.4690 - val_accuracy: 0.7928\n",
      "Epoch 336/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3333 - accuracy: 0.8763 - val_loss: 0.3826 - val_accuracy: 0.8567\n",
      "Epoch 337/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3352 - accuracy: 0.8796 - val_loss: 0.3935 - val_accuracy: 0.8421\n",
      "Epoch 338/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3339 - accuracy: 0.8730 - val_loss: 0.3967 - val_accuracy: 0.8533\n",
      "Epoch 339/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3327 - accuracy: 0.8824 - val_loss: 0.3830 - val_accuracy: 0.8555\n",
      "Epoch 340/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3279 - accuracy: 0.8791 - val_loss: 0.3870 - val_accuracy: 0.8656\n",
      "Epoch 341/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3343 - accuracy: 0.8796 - val_loss: 0.5142 - val_accuracy: 0.8074\n",
      "Epoch 342/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3263 - accuracy: 0.8851 - val_loss: 0.3801 - val_accuracy: 0.8555\n",
      "Epoch 343/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3315 - accuracy: 0.8835 - val_loss: 0.4190 - val_accuracy: 0.8421\n",
      "Epoch 344/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3241 - accuracy: 0.8824 - val_loss: 0.3918 - val_accuracy: 0.8499\n",
      "Epoch 345/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3281 - accuracy: 0.8780 - val_loss: 0.4288 - val_accuracy: 0.8387\n",
      "Epoch 346/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3290 - accuracy: 0.8813 - val_loss: 0.4402 - val_accuracy: 0.8242\n",
      "Epoch 347/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3260 - accuracy: 0.8780 - val_loss: 0.4164 - val_accuracy: 0.8309\n",
      "Epoch 348/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3301 - accuracy: 0.8802 - val_loss: 0.4006 - val_accuracy: 0.8522\n",
      "Epoch 349/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3283 - accuracy: 0.8807 - val_loss: 0.3920 - val_accuracy: 0.8477\n",
      "Epoch 350/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3269 - accuracy: 0.8824 - val_loss: 0.4859 - val_accuracy: 0.8074\n",
      "Epoch 351/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3300 - accuracy: 0.8774 - val_loss: 0.4577 - val_accuracy: 0.8163\n",
      "Epoch 352/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3283 - accuracy: 0.8791 - val_loss: 0.4088 - val_accuracy: 0.8623\n",
      "Epoch 353/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3268 - accuracy: 0.8824 - val_loss: 0.3811 - val_accuracy: 0.8600\n",
      "Epoch 354/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3260 - accuracy: 0.8807 - val_loss: 0.3998 - val_accuracy: 0.8477\n",
      "Epoch 355/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3217 - accuracy: 0.8890 - val_loss: 0.4133 - val_accuracy: 0.8387\n",
      "Epoch 356/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3227 - accuracy: 0.8890 - val_loss: 0.4360 - val_accuracy: 0.8186\n",
      "Epoch 357/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3197 - accuracy: 0.8896 - val_loss: 0.4075 - val_accuracy: 0.8432\n",
      "Epoch 358/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3200 - accuracy: 0.8868 - val_loss: 0.3950 - val_accuracy: 0.8533\n",
      "Epoch 359/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3205 - accuracy: 0.8874 - val_loss: 0.3903 - val_accuracy: 0.8466\n",
      "Epoch 360/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3225 - accuracy: 0.8851 - val_loss: 0.3929 - val_accuracy: 0.8455\n",
      "Epoch 361/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3231 - accuracy: 0.8885 - val_loss: 0.3746 - val_accuracy: 0.8522\n",
      "Epoch 362/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3218 - accuracy: 0.8840 - val_loss: 0.3870 - val_accuracy: 0.8578\n",
      "Epoch 363/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3199 - accuracy: 0.8885 - val_loss: 0.4127 - val_accuracy: 0.8242\n",
      "Epoch 364/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3224 - accuracy: 0.8890 - val_loss: 0.3859 - val_accuracy: 0.8522\n",
      "Epoch 365/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3225 - accuracy: 0.8791 - val_loss: 0.3858 - val_accuracy: 0.8499\n",
      "Epoch 366/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3232 - accuracy: 0.8791 - val_loss: 0.4578 - val_accuracy: 0.8163\n",
      "Epoch 367/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3211 - accuracy: 0.8863 - val_loss: 0.3855 - val_accuracy: 0.8499\n",
      "Epoch 368/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3206 - accuracy: 0.8824 - val_loss: 0.5119 - val_accuracy: 0.8085\n",
      "Epoch 369/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3180 - accuracy: 0.8879 - val_loss: 0.3999 - val_accuracy: 0.8567\n",
      "Epoch 370/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3167 - accuracy: 0.8840 - val_loss: 0.3983 - val_accuracy: 0.8544\n",
      "Epoch 371/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3167 - accuracy: 0.8868 - val_loss: 0.3716 - val_accuracy: 0.8511\n",
      "Epoch 372/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3213 - accuracy: 0.8890 - val_loss: 0.3905 - val_accuracy: 0.8511\n",
      "Epoch 373/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3203 - accuracy: 0.8874 - val_loss: 0.3856 - val_accuracy: 0.8679\n",
      "Epoch 374/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3191 - accuracy: 0.8874 - val_loss: 0.3906 - val_accuracy: 0.8488\n",
      "Epoch 375/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3164 - accuracy: 0.8851 - val_loss: 0.4268 - val_accuracy: 0.8264\n",
      "Epoch 376/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3203 - accuracy: 0.8829 - val_loss: 0.4838 - val_accuracy: 0.8096\n",
      "Epoch 377/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3166 - accuracy: 0.8824 - val_loss: 0.3889 - val_accuracy: 0.8533\n",
      "Epoch 378/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3118 - accuracy: 0.8912 - val_loss: 0.3843 - val_accuracy: 0.8455\n",
      "Epoch 379/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3174 - accuracy: 0.8923 - val_loss: 0.3711 - val_accuracy: 0.8567\n",
      "Epoch 380/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3158 - accuracy: 0.8824 - val_loss: 0.4226 - val_accuracy: 0.8186\n",
      "Epoch 381/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3103 - accuracy: 0.8890 - val_loss: 0.3769 - val_accuracy: 0.8690\n",
      "Epoch 382/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3117 - accuracy: 0.8863 - val_loss: 0.3753 - val_accuracy: 0.8634\n",
      "Epoch 383/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3112 - accuracy: 0.8923 - val_loss: 0.4007 - val_accuracy: 0.8466\n",
      "Epoch 384/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3162 - accuracy: 0.8874 - val_loss: 0.4020 - val_accuracy: 0.8477\n",
      "Epoch 385/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3140 - accuracy: 0.8885 - val_loss: 0.3975 - val_accuracy: 0.8623\n",
      "Epoch 386/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3103 - accuracy: 0.8912 - val_loss: 0.3721 - val_accuracy: 0.8746\n",
      "Epoch 387/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3120 - accuracy: 0.8896 - val_loss: 0.3948 - val_accuracy: 0.8376\n",
      "Epoch 388/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3140 - accuracy: 0.8934 - val_loss: 0.4029 - val_accuracy: 0.8432\n",
      "Epoch 389/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3116 - accuracy: 0.8879 - val_loss: 0.3923 - val_accuracy: 0.8499\n",
      "Epoch 390/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3074 - accuracy: 0.8951 - val_loss: 0.3951 - val_accuracy: 0.8466\n",
      "Epoch 391/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3057 - accuracy: 0.8940 - val_loss: 0.3909 - val_accuracy: 0.8555\n",
      "Epoch 392/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3102 - accuracy: 0.8907 - val_loss: 0.3982 - val_accuracy: 0.8410\n",
      "Epoch 393/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3070 - accuracy: 0.8995 - val_loss: 0.3843 - val_accuracy: 0.8499\n",
      "Epoch 394/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3087 - accuracy: 0.8896 - val_loss: 0.3939 - val_accuracy: 0.8354\n",
      "Epoch 395/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3071 - accuracy: 0.8918 - val_loss: 0.4124 - val_accuracy: 0.8567\n",
      "Epoch 396/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3085 - accuracy: 0.8851 - val_loss: 0.4108 - val_accuracy: 0.8331\n",
      "Epoch 397/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3119 - accuracy: 0.8846 - val_loss: 0.3761 - val_accuracy: 0.8667\n",
      "Epoch 398/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3072 - accuracy: 0.8923 - val_loss: 0.3750 - val_accuracy: 0.8578\n",
      "Epoch 399/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3081 - accuracy: 0.8929 - val_loss: 0.3904 - val_accuracy: 0.8466\n",
      "Epoch 400/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3086 - accuracy: 0.8907 - val_loss: 0.3679 - val_accuracy: 0.8611\n",
      "Epoch 401/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3055 - accuracy: 0.8940 - val_loss: 0.4510 - val_accuracy: 0.8320\n",
      "Epoch 402/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3063 - accuracy: 0.8923 - val_loss: 0.3835 - val_accuracy: 0.8466\n",
      "Epoch 403/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2982 - accuracy: 0.8940 - val_loss: 0.3752 - val_accuracy: 0.8701\n",
      "Epoch 404/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3070 - accuracy: 0.8890 - val_loss: 0.4021 - val_accuracy: 0.8387\n",
      "Epoch 405/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3062 - accuracy: 0.8885 - val_loss: 0.3668 - val_accuracy: 0.8679\n",
      "Epoch 406/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3005 - accuracy: 0.8934 - val_loss: 0.3951 - val_accuracy: 0.8499\n",
      "Epoch 407/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3047 - accuracy: 0.8890 - val_loss: 0.3734 - val_accuracy: 0.8623\n",
      "Epoch 408/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3074 - accuracy: 0.8863 - val_loss: 0.4136 - val_accuracy: 0.8522\n",
      "Epoch 409/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3017 - accuracy: 0.8901 - val_loss: 0.3927 - val_accuracy: 0.8466\n",
      "Epoch 410/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2963 - accuracy: 0.8879 - val_loss: 0.4570 - val_accuracy: 0.8387\n",
      "Epoch 411/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3018 - accuracy: 0.8912 - val_loss: 0.3732 - val_accuracy: 0.8600\n",
      "Epoch 412/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3030 - accuracy: 0.8923 - val_loss: 0.3962 - val_accuracy: 0.8511\n",
      "Epoch 413/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3007 - accuracy: 0.8973 - val_loss: 0.3977 - val_accuracy: 0.8466\n",
      "Epoch 414/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2979 - accuracy: 0.8907 - val_loss: 0.3694 - val_accuracy: 0.8634\n",
      "Epoch 415/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3018 - accuracy: 0.8929 - val_loss: 0.3815 - val_accuracy: 0.8645\n",
      "Epoch 416/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3025 - accuracy: 0.8940 - val_loss: 0.4110 - val_accuracy: 0.8555\n",
      "Epoch 417/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3009 - accuracy: 0.8879 - val_loss: 0.3872 - val_accuracy: 0.8611\n",
      "Epoch 418/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3004 - accuracy: 0.8923 - val_loss: 0.3964 - val_accuracy: 0.8522\n",
      "Epoch 419/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.3043 - accuracy: 0.8945 - val_loss: 0.3885 - val_accuracy: 0.8645\n",
      "Epoch 420/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2986 - accuracy: 0.8934 - val_loss: 0.3916 - val_accuracy: 0.8466\n",
      "Epoch 421/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2999 - accuracy: 0.8824 - val_loss: 0.3669 - val_accuracy: 0.8522\n",
      "Epoch 422/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2990 - accuracy: 0.8901 - val_loss: 0.4230 - val_accuracy: 0.8264\n",
      "Epoch 423/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2994 - accuracy: 0.8940 - val_loss: 0.3602 - val_accuracy: 0.8611\n",
      "Epoch 424/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2985 - accuracy: 0.8885 - val_loss: 0.3712 - val_accuracy: 0.8634\n",
      "Epoch 425/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2982 - accuracy: 0.8929 - val_loss: 0.3689 - val_accuracy: 0.8555\n",
      "Epoch 426/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2973 - accuracy: 0.8934 - val_loss: 0.3608 - val_accuracy: 0.8634\n",
      "Epoch 427/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2978 - accuracy: 0.8907 - val_loss: 0.3601 - val_accuracy: 0.8667\n",
      "Epoch 428/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2931 - accuracy: 0.8918 - val_loss: 0.3597 - val_accuracy: 0.8723\n",
      "Epoch 429/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2977 - accuracy: 0.8934 - val_loss: 0.3899 - val_accuracy: 0.8499\n",
      "Epoch 430/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2938 - accuracy: 0.8907 - val_loss: 0.3649 - val_accuracy: 0.8645\n",
      "Epoch 431/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2932 - accuracy: 0.8934 - val_loss: 0.4139 - val_accuracy: 0.8578\n",
      "Epoch 432/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2927 - accuracy: 0.8945 - val_loss: 0.3967 - val_accuracy: 0.8331\n",
      "Epoch 433/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2945 - accuracy: 0.8874 - val_loss: 0.3738 - val_accuracy: 0.8712\n",
      "Epoch 434/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2946 - accuracy: 0.8956 - val_loss: 0.3596 - val_accuracy: 0.8690\n",
      "Epoch 435/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2959 - accuracy: 0.8951 - val_loss: 0.3587 - val_accuracy: 0.8679\n",
      "Epoch 436/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2940 - accuracy: 0.8978 - val_loss: 0.3832 - val_accuracy: 0.8511\n",
      "Epoch 437/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2956 - accuracy: 0.8945 - val_loss: 0.3898 - val_accuracy: 0.8477\n",
      "Epoch 438/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2933 - accuracy: 0.8918 - val_loss: 0.4384 - val_accuracy: 0.8163\n",
      "Epoch 439/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2919 - accuracy: 0.8940 - val_loss: 0.4673 - val_accuracy: 0.8163\n",
      "Epoch 440/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2924 - accuracy: 0.8967 - val_loss: 0.4198 - val_accuracy: 0.8544\n",
      "Epoch 441/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2912 - accuracy: 0.8973 - val_loss: 0.4009 - val_accuracy: 0.8667\n",
      "Epoch 442/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2894 - accuracy: 0.8951 - val_loss: 0.4000 - val_accuracy: 0.8477\n",
      "Epoch 443/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2913 - accuracy: 0.8901 - val_loss: 0.3906 - val_accuracy: 0.8555\n",
      "Epoch 444/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2884 - accuracy: 0.8901 - val_loss: 0.3691 - val_accuracy: 0.8600\n",
      "Epoch 445/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2923 - accuracy: 0.8962 - val_loss: 0.3674 - val_accuracy: 0.8723\n",
      "Epoch 446/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2924 - accuracy: 0.8890 - val_loss: 0.4060 - val_accuracy: 0.8421\n",
      "Epoch 447/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2866 - accuracy: 0.9006 - val_loss: 0.4134 - val_accuracy: 0.8287\n",
      "Epoch 448/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2896 - accuracy: 0.8951 - val_loss: 0.4700 - val_accuracy: 0.8007\n",
      "Epoch 449/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2931 - accuracy: 0.8923 - val_loss: 0.3554 - val_accuracy: 0.8656\n",
      "Epoch 450/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2886 - accuracy: 0.9023 - val_loss: 0.3967 - val_accuracy: 0.8365\n",
      "Epoch 451/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2893 - accuracy: 0.8940 - val_loss: 0.4720 - val_accuracy: 0.8119\n",
      "Epoch 452/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2899 - accuracy: 0.9006 - val_loss: 0.4134 - val_accuracy: 0.8275\n",
      "Epoch 453/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2898 - accuracy: 0.9023 - val_loss: 0.3945 - val_accuracy: 0.8477\n",
      "Epoch 454/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2889 - accuracy: 0.8896 - val_loss: 0.4092 - val_accuracy: 0.8567\n",
      "Epoch 455/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2882 - accuracy: 0.8973 - val_loss: 0.3928 - val_accuracy: 0.8455\n",
      "Epoch 456/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2866 - accuracy: 0.8945 - val_loss: 0.4181 - val_accuracy: 0.8555\n",
      "Epoch 457/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2847 - accuracy: 0.8973 - val_loss: 0.4723 - val_accuracy: 0.8287\n",
      "Epoch 458/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2872 - accuracy: 0.8978 - val_loss: 0.3611 - val_accuracy: 0.8555\n",
      "Epoch 459/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2863 - accuracy: 0.8918 - val_loss: 0.3644 - val_accuracy: 0.8634\n",
      "Epoch 460/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2851 - accuracy: 0.9012 - val_loss: 0.3649 - val_accuracy: 0.8600\n",
      "Epoch 461/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2858 - accuracy: 0.9012 - val_loss: 0.3655 - val_accuracy: 0.8611\n",
      "Epoch 462/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2895 - accuracy: 0.8907 - val_loss: 0.3871 - val_accuracy: 0.8477\n",
      "Epoch 463/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2846 - accuracy: 0.8978 - val_loss: 0.3563 - val_accuracy: 0.8567\n",
      "Epoch 464/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2827 - accuracy: 0.8978 - val_loss: 0.3775 - val_accuracy: 0.8511\n",
      "Epoch 465/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2858 - accuracy: 0.8995 - val_loss: 0.3809 - val_accuracy: 0.8399\n",
      "Epoch 466/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2843 - accuracy: 0.9039 - val_loss: 0.3704 - val_accuracy: 0.8679\n",
      "Epoch 467/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2851 - accuracy: 0.9050 - val_loss: 0.3560 - val_accuracy: 0.8623\n",
      "Epoch 468/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2833 - accuracy: 0.8978 - val_loss: 0.3597 - val_accuracy: 0.8567\n",
      "Epoch 469/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2846 - accuracy: 0.9012 - val_loss: 0.3519 - val_accuracy: 0.8634\n",
      "Epoch 470/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2776 - accuracy: 0.9012 - val_loss: 0.4321 - val_accuracy: 0.8287\n",
      "Epoch 471/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2827 - accuracy: 0.8984 - val_loss: 0.3800 - val_accuracy: 0.8623\n",
      "Epoch 472/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2797 - accuracy: 0.9001 - val_loss: 0.3533 - val_accuracy: 0.8611\n",
      "Epoch 473/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2822 - accuracy: 0.8918 - val_loss: 0.3570 - val_accuracy: 0.8589\n",
      "Epoch 474/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2809 - accuracy: 0.9067 - val_loss: 0.5165 - val_accuracy: 0.7805\n",
      "Epoch 475/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2857 - accuracy: 0.9006 - val_loss: 0.3513 - val_accuracy: 0.8645\n",
      "Epoch 476/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2769 - accuracy: 0.9072 - val_loss: 0.4134 - val_accuracy: 0.8432\n",
      "Epoch 477/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2796 - accuracy: 0.8973 - val_loss: 0.4316 - val_accuracy: 0.8298\n",
      "Epoch 478/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2808 - accuracy: 0.8956 - val_loss: 0.3988 - val_accuracy: 0.8667\n",
      "Epoch 479/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2810 - accuracy: 0.9056 - val_loss: 0.3622 - val_accuracy: 0.8589\n",
      "Epoch 480/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2821 - accuracy: 0.8990 - val_loss: 0.3656 - val_accuracy: 0.8544\n",
      "Epoch 481/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2770 - accuracy: 0.9034 - val_loss: 0.3604 - val_accuracy: 0.8611\n",
      "Epoch 482/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2785 - accuracy: 0.9039 - val_loss: 0.3615 - val_accuracy: 0.8600\n",
      "Epoch 483/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2804 - accuracy: 0.9028 - val_loss: 0.4272 - val_accuracy: 0.8208\n",
      "Epoch 484/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2778 - accuracy: 0.9028 - val_loss: 0.4001 - val_accuracy: 0.8679\n",
      "Epoch 485/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2776 - accuracy: 0.8995 - val_loss: 0.3793 - val_accuracy: 0.8522\n",
      "Epoch 486/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2735 - accuracy: 0.8984 - val_loss: 0.4001 - val_accuracy: 0.8533\n",
      "Epoch 487/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2770 - accuracy: 0.8945 - val_loss: 0.3737 - val_accuracy: 0.8712\n",
      "Epoch 488/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2759 - accuracy: 0.9056 - val_loss: 0.3649 - val_accuracy: 0.8600\n",
      "Epoch 489/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2765 - accuracy: 0.8967 - val_loss: 0.4075 - val_accuracy: 0.8432\n",
      "Epoch 490/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2788 - accuracy: 0.9039 - val_loss: 0.3880 - val_accuracy: 0.8387\n",
      "Epoch 491/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2748 - accuracy: 0.9006 - val_loss: 0.4079 - val_accuracy: 0.8567\n",
      "Epoch 492/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2771 - accuracy: 0.8990 - val_loss: 0.3630 - val_accuracy: 0.8611\n",
      "Epoch 493/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2760 - accuracy: 0.9045 - val_loss: 0.3476 - val_accuracy: 0.8735\n",
      "Epoch 494/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2749 - accuracy: 0.9039 - val_loss: 0.4356 - val_accuracy: 0.8219\n",
      "Epoch 495/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2738 - accuracy: 0.9034 - val_loss: 0.4398 - val_accuracy: 0.8163\n",
      "Epoch 496/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2788 - accuracy: 0.9012 - val_loss: 0.4114 - val_accuracy: 0.8320\n",
      "Epoch 497/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2766 - accuracy: 0.8984 - val_loss: 0.3470 - val_accuracy: 0.8634\n",
      "Epoch 498/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2746 - accuracy: 0.9001 - val_loss: 0.3850 - val_accuracy: 0.8387\n",
      "Epoch 499/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2772 - accuracy: 0.9023 - val_loss: 0.3897 - val_accuracy: 0.8432\n",
      "Epoch 500/500\n",
      "114/114 [==============================] - 1s 6ms/step - loss: 0.2749 - accuracy: 0.8940 - val_loss: 0.3499 - val_accuracy: 0.8589\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=500, validation_data=(x_testcnn, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "J1mJrn3LtO_M",
    "outputId": "dd7622a7-83e0-49ad-dbf2-09cb38c95883"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "8tkiuu1VvF-Q",
    "outputId": "52115e47-e0c9-48fa-ef88-fca7882a0ee3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(cnnhistory.history['accuracy'])\n",
    "plt.plot(cnnhistory.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o5sfY2VBvRxw",
    "outputId": "9a32a2ca-1b3c-456c-e30f-ca5bc7691b2a"
   },
   "outputs": [],
   "source": [
    "\n",
    "predictions = model.predict_classes(x_testcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fHbShhLDvrmH",
    "outputId": "72536883-4960-40c9-aeb0-6c40447e526a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 2, 3, 3, 2, 2, 1, 3, 3, 2, 4, 2, 3, 2, 1, 3, 2, 4, 1, 3, 4,\n",
       "       2, 4, 3, 1, 3, 4, 3, 3, 4, 3, 2, 1, 2, 2, 4, 3, 4, 3, 2, 2, 3, 2,\n",
       "       1, 1, 1, 4, 4, 3, 3, 3, 4, 2, 2, 2, 3, 1, 3, 4, 1, 3, 4, 3, 3, 3,\n",
       "       2, 4, 4, 3, 1, 4, 2, 2, 2, 3, 2, 3, 2, 4, 1, 3, 4, 1, 2, 4, 3, 1,\n",
       "       1, 3, 2, 2, 3, 2, 4, 3, 3, 3, 4, 2, 1, 4, 3, 4, 2, 1, 4, 3, 1, 2,\n",
       "       3, 3, 4, 3, 4, 3, 3, 4, 4, 4, 2, 4, 4, 1, 4, 4, 1, 4, 4, 3, 4, 1,\n",
       "       3, 3, 4, 4, 3, 3, 1, 3, 4, 3, 2, 4, 4, 4, 2, 2, 2, 1, 3, 3, 2, 3,\n",
       "       2, 3, 2, 2, 2, 3, 2, 3, 4, 1, 4, 4, 2, 2, 4, 4, 4, 4, 2, 4, 4, 2,\n",
       "       1, 3, 1, 3, 4, 3, 3, 3, 3, 4, 3, 2, 1, 2, 4, 4, 1, 4, 2, 4, 4, 2,\n",
       "       3, 2, 2, 3, 3, 4, 4, 4, 4, 4, 4, 4, 2, 3, 3, 3, 3, 1, 2, 2, 3, 3,\n",
       "       1, 1, 2, 2, 1, 3, 4, 4, 4, 3, 4, 1, 3, 2, 3, 2, 3, 2, 3, 4, 3, 2,\n",
       "       1, 3, 4, 2, 4, 1, 3, 3, 3, 4, 2, 2, 3, 4, 1, 3, 4, 1, 3, 1, 2, 1,\n",
       "       4, 3, 4, 4, 4, 4, 2, 2, 2, 3, 4, 4, 3, 2, 4, 3, 1, 2, 4, 1, 2, 4,\n",
       "       4, 4, 3, 4, 3, 3, 2, 1, 1, 3, 1, 4, 4, 4, 1, 3, 4, 4, 4, 1, 4, 4,\n",
       "       2, 3, 3, 2, 3, 4, 3, 1, 3, 2, 1, 3, 3, 1, 4, 2, 4, 3, 2, 3, 1, 2,\n",
       "       1, 3, 2, 1, 1, 4, 2, 2, 4, 3, 2, 3, 4, 2, 3, 3, 3, 4, 3, 4, 4, 3,\n",
       "       2, 4, 3, 3, 2, 4, 3, 4, 4, 3, 2, 4, 4, 3, 3, 1, 4, 4, 3, 2, 2, 2,\n",
       "       2, 3, 2, 4, 3, 3, 4, 3, 2, 4, 3, 4, 4, 2, 1, 4, 4, 1, 1, 1, 4, 3,\n",
       "       4, 4, 4, 4, 2, 4, 2, 2, 3, 2, 4, 3, 2, 2, 4, 2, 2, 4, 3, 1, 2, 4,\n",
       "       3, 4, 2, 3, 4, 3, 4, 3, 1, 4, 4, 2, 2, 4, 4, 1, 2, 4, 2, 3, 3, 2,\n",
       "       2, 2, 4, 4, 3, 2, 4, 2, 2, 3, 4, 2, 1, 1, 3, 1, 3, 3, 4, 3, 3, 3,\n",
       "       1, 4, 1, 3, 4, 4, 3, 2, 4, 4, 3, 4, 2, 3, 3, 3, 3, 2, 2, 4, 4, 1,\n",
       "       4, 1, 4, 2, 4, 3, 1, 3, 4, 1, 3, 1, 4, 2, 3, 4, 3, 1, 1, 2, 1, 3,\n",
       "       2, 3, 4, 3, 1, 1, 2, 4, 4, 3, 1, 4, 4, 2, 1, 3, 2, 4, 2, 4, 2, 4,\n",
       "       3, 3, 3, 2, 4, 3, 2, 4, 1, 4, 4, 2, 4, 4, 4, 4, 2, 3, 4, 4, 2, 1,\n",
       "       3, 2, 4, 3, 2, 4, 2, 2, 1, 3, 2, 1, 3, 2, 2, 4, 1, 3, 4, 1, 4, 1,\n",
       "       2, 2, 4, 2, 4, 4, 3, 2, 4, 4, 2, 2, 2, 3, 4, 4, 2, 3, 2, 3, 1, 1,\n",
       "       3, 3, 1, 3, 2, 1, 3, 3, 4, 1, 4, 3, 3, 3, 1, 2, 3, 4, 2, 2, 4, 1,\n",
       "       4, 3, 4, 4, 2, 2, 2, 2, 3, 3, 4, 4, 3, 2, 4, 3, 2, 3, 4, 2, 3, 3,\n",
       "       4, 4, 1, 3, 4, 3, 4, 4, 3, 1, 4, 4, 2, 2, 4, 2, 2, 4, 3, 1, 3, 2,\n",
       "       4, 4, 1, 4, 3, 3, 2, 3, 2, 4, 4, 3, 3, 4, 3, 1, 2, 3, 2, 2, 3, 4,\n",
       "       4, 2, 2, 1, 4, 3, 4, 2, 3, 4, 1, 3, 3, 1, 4, 3, 4, 2, 2, 4, 4, 1,\n",
       "       2, 2, 2, 2, 3, 4, 2, 3, 3, 3, 1, 1, 3, 4, 4, 2, 3, 2, 3, 3, 4, 2,\n",
       "       3, 1, 4, 3, 3, 2, 4, 4, 3, 2, 4, 2, 2, 2, 3, 1, 4, 4, 4, 2, 1, 4,\n",
       "       3, 3, 1, 4, 1, 2, 3, 4, 4, 3, 3, 4, 3, 3, 4, 1, 2, 4, 1, 4, 2, 3,\n",
       "       4, 4, 3, 3, 2, 3, 2, 2, 3, 2, 3, 4, 4, 2, 4, 2, 4, 1, 4, 4, 2, 1,\n",
       "       3, 3, 3, 1, 2, 3, 2, 4, 3, 3, 3, 4, 3, 4, 2, 4, 2, 1, 3, 3, 2, 3,\n",
       "       2, 3, 2, 3, 4, 2, 3, 3, 4, 4, 4, 4, 4, 3, 2, 1, 4, 1, 2, 2, 4, 3,\n",
       "       3, 3, 3, 2, 1, 4, 4, 4, 1, 3, 1, 2, 1, 2, 2, 4, 2, 3, 4, 1, 2, 2,\n",
       "       1, 4, 1, 2, 3, 2, 3, 1, 4, 1, 2, 3, 4, 3, 3, 1, 3, 2, 2, 1, 3, 2,\n",
       "       1, 1, 4, 2, 3, 2, 1, 2, 4, 2, 4, 4, 2], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9vH2vedFvt_5",
    "outputId": "1b717561-fe78-4b73-8140-fc7f8b3bd655"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 2, 3, 3, 2, 2, 2, 3, 3, 2, 3, 2, 3, 2, 1, 1, 2, 2, 1, 3, 4,\n",
       "       2, 2, 3, 1, 2, 4, 3, 1, 4, 3, 2, 3, 2, 2, 4, 3, 4, 3, 2, 2, 3, 2,\n",
       "       1, 1, 1, 4, 2, 3, 3, 3, 4, 2, 2, 2, 3, 3, 3, 4, 1, 3, 4, 3, 3, 3,\n",
       "       2, 4, 4, 4, 2, 4, 2, 4, 2, 3, 2, 3, 2, 4, 1, 3, 4, 1, 1, 4, 3, 1,\n",
       "       4, 3, 2, 2, 3, 2, 4, 3, 2, 3, 4, 2, 1, 4, 1, 4, 2, 1, 2, 3, 1, 2,\n",
       "       3, 1, 4, 3, 4, 3, 3, 4, 4, 4, 2, 4, 4, 2, 4, 4, 1, 2, 4, 3, 4, 1,\n",
       "       3, 3, 4, 4, 3, 2, 1, 3, 4, 3, 2, 4, 4, 4, 2, 2, 2, 2, 3, 3, 2, 3,\n",
       "       2, 3, 2, 2, 2, 4, 2, 3, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 2, 4, 4, 2,\n",
       "       2, 3, 1, 3, 4, 3, 3, 3, 3, 4, 3, 2, 1, 2, 3, 2, 1, 4, 4, 2, 4, 2,\n",
       "       3, 2, 2, 1, 3, 4, 4, 4, 4, 4, 1, 4, 2, 3, 3, 3, 3, 1, 3, 2, 3, 3,\n",
       "       1, 1, 2, 2, 1, 3, 4, 4, 4, 2, 2, 1, 3, 2, 3, 2, 3, 2, 1, 4, 3, 3,\n",
       "       2, 3, 3, 2, 2, 1, 3, 4, 1, 4, 2, 2, 3, 4, 2, 3, 4, 1, 3, 1, 2, 1,\n",
       "       4, 3, 4, 4, 4, 2, 2, 2, 2, 3, 4, 1, 3, 2, 4, 2, 4, 2, 4, 1, 2, 4,\n",
       "       3, 4, 3, 4, 3, 3, 2, 1, 1, 3, 2, 4, 2, 4, 1, 3, 4, 4, 4, 1, 2, 4,\n",
       "       1, 3, 3, 2, 3, 4, 2, 1, 1, 2, 3, 3, 3, 4, 4, 2, 4, 3, 2, 3, 1, 2,\n",
       "       1, 3, 2, 1, 1, 4, 2, 2, 3, 3, 2, 3, 4, 2, 3, 3, 3, 4, 2, 2, 4, 3,\n",
       "       2, 4, 3, 3, 2, 4, 3, 4, 4, 3, 2, 4, 4, 3, 3, 1, 4, 4, 3, 2, 2, 2,\n",
       "       2, 3, 2, 4, 3, 3, 4, 3, 2, 4, 3, 4, 4, 2, 3, 4, 4, 1, 1, 1, 4, 3,\n",
       "       4, 4, 4, 4, 2, 4, 2, 2, 3, 2, 4, 3, 2, 2, 4, 2, 2, 4, 3, 1, 2, 4,\n",
       "       2, 4, 2, 3, 4, 3, 4, 3, 3, 4, 4, 2, 2, 4, 4, 2, 2, 1, 2, 3, 3, 2,\n",
       "       3, 2, 4, 4, 3, 2, 4, 2, 2, 2, 4, 2, 1, 1, 3, 1, 3, 3, 4, 3, 3, 3,\n",
       "       1, 4, 3, 3, 4, 4, 3, 2, 4, 4, 3, 3, 4, 3, 3, 3, 4, 2, 2, 2, 4, 3,\n",
       "       4, 2, 4, 2, 4, 3, 1, 4, 4, 3, 4, 1, 4, 2, 3, 4, 3, 1, 1, 2, 1, 3,\n",
       "       2, 3, 4, 3, 1, 1, 2, 4, 4, 3, 1, 4, 4, 2, 1, 3, 2, 4, 2, 4, 2, 4,\n",
       "       3, 2, 3, 4, 4, 3, 2, 4, 1, 4, 4, 2, 4, 4, 4, 4, 2, 1, 4, 4, 2, 1,\n",
       "       3, 2, 4, 3, 2, 4, 2, 2, 1, 3, 2, 1, 3, 3, 2, 4, 1, 3, 4, 1, 4, 2,\n",
       "       2, 1, 4, 2, 4, 4, 3, 1, 4, 4, 2, 2, 2, 3, 4, 4, 2, 2, 2, 3, 1, 1,\n",
       "       3, 3, 1, 3, 2, 3, 3, 3, 4, 1, 4, 3, 3, 4, 1, 2, 3, 4, 2, 2, 4, 1,\n",
       "       4, 3, 4, 4, 2, 2, 2, 2, 3, 3, 4, 4, 3, 1, 4, 3, 1, 1, 4, 2, 3, 3,\n",
       "       4, 4, 3, 3, 4, 3, 4, 4, 3, 1, 4, 4, 2, 3, 4, 4, 2, 4, 3, 1, 3, 2,\n",
       "       3, 4, 1, 4, 3, 3, 2, 3, 2, 4, 2, 3, 3, 3, 3, 2, 2, 3, 2, 2, 3, 4,\n",
       "       4, 2, 2, 1, 4, 3, 4, 2, 2, 4, 1, 3, 3, 1, 4, 1, 4, 2, 2, 2, 4, 1,\n",
       "       3, 2, 2, 2, 3, 4, 2, 1, 2, 3, 1, 1, 4, 4, 4, 2, 2, 4, 3, 3, 4, 2,\n",
       "       3, 2, 4, 3, 3, 2, 4, 4, 3, 2, 2, 2, 2, 2, 3, 1, 4, 2, 4, 2, 1, 4,\n",
       "       3, 3, 1, 4, 3, 2, 3, 1, 2, 3, 3, 4, 3, 3, 4, 1, 3, 4, 1, 4, 2, 3,\n",
       "       4, 4, 3, 3, 2, 3, 2, 2, 3, 2, 3, 4, 4, 2, 4, 2, 4, 1, 4, 4, 2, 1,\n",
       "       3, 3, 3, 1, 3, 3, 2, 4, 3, 3, 1, 4, 3, 4, 2, 4, 2, 3, 3, 3, 2, 3,\n",
       "       2, 3, 2, 3, 4, 2, 4, 3, 4, 4, 4, 4, 4, 3, 2, 3, 4, 1, 2, 2, 4, 2,\n",
       "       3, 3, 3, 2, 4, 4, 4, 4, 3, 3, 1, 2, 1, 2, 1, 1, 2, 3, 4, 1, 1, 1,\n",
       "       1, 4, 1, 2, 3, 2, 3, 2, 4, 1, 2, 3, 4, 3, 3, 2, 3, 2, 2, 1, 3, 2,\n",
       "       1, 1, 4, 2, 3, 2, 1, 2, 4, 2, 4, 4, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "plKFIfuPv5qt"
   },
   "outputs": [],
   "source": [
    "\n",
    "new_Ytest = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZrXYkj7Nv9kk",
    "outputId": "fd0f5ca1-2eed-4f6d-8ae4-8acefc655b61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 2, 3, 3, 2, 2, 2, 3, 3, 2, 3, 2, 3, 2, 1, 1, 2, 2, 1, 3, 4,\n",
       "       2, 2, 3, 1, 2, 4, 3, 1, 4, 3, 2, 3, 2, 2, 4, 3, 4, 3, 2, 2, 3, 2,\n",
       "       1, 1, 1, 4, 2, 3, 3, 3, 4, 2, 2, 2, 3, 3, 3, 4, 1, 3, 4, 3, 3, 3,\n",
       "       2, 4, 4, 4, 2, 4, 2, 4, 2, 3, 2, 3, 2, 4, 1, 3, 4, 1, 1, 4, 3, 1,\n",
       "       4, 3, 2, 2, 3, 2, 4, 3, 2, 3, 4, 2, 1, 4, 1, 4, 2, 1, 2, 3, 1, 2,\n",
       "       3, 1, 4, 3, 4, 3, 3, 4, 4, 4, 2, 4, 4, 2, 4, 4, 1, 2, 4, 3, 4, 1,\n",
       "       3, 3, 4, 4, 3, 2, 1, 3, 4, 3, 2, 4, 4, 4, 2, 2, 2, 2, 3, 3, 2, 3,\n",
       "       2, 3, 2, 2, 2, 4, 2, 3, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 2, 4, 4, 2,\n",
       "       2, 3, 1, 3, 4, 3, 3, 3, 3, 4, 3, 2, 1, 2, 3, 2, 1, 4, 4, 2, 4, 2,\n",
       "       3, 2, 2, 1, 3, 4, 4, 4, 4, 4, 1, 4, 2, 3, 3, 3, 3, 1, 3, 2, 3, 3,\n",
       "       1, 1, 2, 2, 1, 3, 4, 4, 4, 2, 2, 1, 3, 2, 3, 2, 3, 2, 1, 4, 3, 3,\n",
       "       2, 3, 3, 2, 2, 1, 3, 4, 1, 4, 2, 2, 3, 4, 2, 3, 4, 1, 3, 1, 2, 1,\n",
       "       4, 3, 4, 4, 4, 2, 2, 2, 2, 3, 4, 1, 3, 2, 4, 2, 4, 2, 4, 1, 2, 4,\n",
       "       3, 4, 3, 4, 3, 3, 2, 1, 1, 3, 2, 4, 2, 4, 1, 3, 4, 4, 4, 1, 2, 4,\n",
       "       1, 3, 3, 2, 3, 4, 2, 1, 1, 2, 3, 3, 3, 4, 4, 2, 4, 3, 2, 3, 1, 2,\n",
       "       1, 3, 2, 1, 1, 4, 2, 2, 3, 3, 2, 3, 4, 2, 3, 3, 3, 4, 2, 2, 4, 3,\n",
       "       2, 4, 3, 3, 2, 4, 3, 4, 4, 3, 2, 4, 4, 3, 3, 1, 4, 4, 3, 2, 2, 2,\n",
       "       2, 3, 2, 4, 3, 3, 4, 3, 2, 4, 3, 4, 4, 2, 3, 4, 4, 1, 1, 1, 4, 3,\n",
       "       4, 4, 4, 4, 2, 4, 2, 2, 3, 2, 4, 3, 2, 2, 4, 2, 2, 4, 3, 1, 2, 4,\n",
       "       2, 4, 2, 3, 4, 3, 4, 3, 3, 4, 4, 2, 2, 4, 4, 2, 2, 1, 2, 3, 3, 2,\n",
       "       3, 2, 4, 4, 3, 2, 4, 2, 2, 2, 4, 2, 1, 1, 3, 1, 3, 3, 4, 3, 3, 3,\n",
       "       1, 4, 3, 3, 4, 4, 3, 2, 4, 4, 3, 3, 4, 3, 3, 3, 4, 2, 2, 2, 4, 3,\n",
       "       4, 2, 4, 2, 4, 3, 1, 4, 4, 3, 4, 1, 4, 2, 3, 4, 3, 1, 1, 2, 1, 3,\n",
       "       2, 3, 4, 3, 1, 1, 2, 4, 4, 3, 1, 4, 4, 2, 1, 3, 2, 4, 2, 4, 2, 4,\n",
       "       3, 2, 3, 4, 4, 3, 2, 4, 1, 4, 4, 2, 4, 4, 4, 4, 2, 1, 4, 4, 2, 1,\n",
       "       3, 2, 4, 3, 2, 4, 2, 2, 1, 3, 2, 1, 3, 3, 2, 4, 1, 3, 4, 1, 4, 2,\n",
       "       2, 1, 4, 2, 4, 4, 3, 1, 4, 4, 2, 2, 2, 3, 4, 4, 2, 2, 2, 3, 1, 1,\n",
       "       3, 3, 1, 3, 2, 3, 3, 3, 4, 1, 4, 3, 3, 4, 1, 2, 3, 4, 2, 2, 4, 1,\n",
       "       4, 3, 4, 4, 2, 2, 2, 2, 3, 3, 4, 4, 3, 1, 4, 3, 1, 1, 4, 2, 3, 3,\n",
       "       4, 4, 3, 3, 4, 3, 4, 4, 3, 1, 4, 4, 2, 3, 4, 4, 2, 4, 3, 1, 3, 2,\n",
       "       3, 4, 1, 4, 3, 3, 2, 3, 2, 4, 2, 3, 3, 3, 3, 2, 2, 3, 2, 2, 3, 4,\n",
       "       4, 2, 2, 1, 4, 3, 4, 2, 2, 4, 1, 3, 3, 1, 4, 1, 4, 2, 2, 2, 4, 1,\n",
       "       3, 2, 2, 2, 3, 4, 2, 1, 2, 3, 1, 1, 4, 4, 4, 2, 2, 4, 3, 3, 4, 2,\n",
       "       3, 2, 4, 3, 3, 2, 4, 4, 3, 2, 2, 2, 2, 2, 3, 1, 4, 2, 4, 2, 1, 4,\n",
       "       3, 3, 1, 4, 3, 2, 3, 1, 2, 3, 3, 4, 3, 3, 4, 1, 3, 4, 1, 4, 2, 3,\n",
       "       4, 4, 3, 3, 2, 3, 2, 2, 3, 2, 3, 4, 4, 2, 4, 2, 4, 1, 4, 4, 2, 1,\n",
       "       3, 3, 3, 1, 3, 3, 2, 4, 3, 3, 1, 4, 3, 4, 2, 4, 2, 3, 3, 3, 2, 3,\n",
       "       2, 3, 2, 3, 4, 2, 4, 3, 4, 4, 4, 4, 4, 3, 2, 3, 4, 1, 2, 2, 4, 2,\n",
       "       3, 3, 3, 2, 4, 4, 4, 4, 3, 3, 1, 2, 1, 2, 1, 1, 2, 3, 4, 1, 1, 1,\n",
       "       1, 4, 1, 2, 3, 2, 3, 2, 4, 1, 2, 3, 4, 3, 3, 2, 3, 2, 2, 1, 3, 2,\n",
       "       1, 1, 4, 2, 3, 2, 1, 2, 4, 2, 4, 4, 2])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_Ytest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_flEUVPzwAL4",
    "outputId": "5f5a437b-0820-44d0-d31e-e29f3f894cb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.78      0.76       123\n",
      "           2       0.90      0.81      0.85       253\n",
      "           3       0.86      0.88      0.87       255\n",
      "           4       0.88      0.92      0.90       262\n",
      "\n",
      "    accuracy                           0.86       893\n",
      "   macro avg       0.84      0.85      0.85       893\n",
      "weighted avg       0.86      0.86      0.86       893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(new_Ytest, predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oqlScGNSwDm2",
    "outputId": "9be160b3-19ce-4bac-e883-c6cab9c2bb4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 96   9  13   5]\n",
      " [ 15 204  15  19]\n",
      " [ 14   8 225   8]\n",
      " [  5   6   9 242]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(new_Ytest, predictions)\n",
    "print (matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8UYn63ODwKwu",
    "outputId": "f4d8d56c-bf99-4790-f43b-b93e35acd4f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at D:/mini project/Models/Emotion_Voice_Detection_Model.h5 \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflowjs as tfjs\n",
    "model_name = 'Emotion_Voice_Detection_Model.h5'\n",
    "save_dir = 'D:/mini project/Models/'\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "model_ts_name = 'Emotion_Voice_Detection_ts_Model.h5'\n",
    "save_ts_dir = 'D:/mini project/Models/'\n",
    "if not os.path.isdir(save_ts_dir):\n",
    "    os.makedirs(save_ts_dir)\n",
    "model_ts_path = os.path.join(save_ts_dir, model_ts_name)\n",
    "tfjs.converters.save_keras_model(model,model_ts_path)\n",
    "\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJubZVnwwODI",
    "outputId": "d45fad1a-d901-4c85-eab3-f7f64b0cc957"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 40, 128)           768       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 5, 128)            82048     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 5128      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 87,944\n",
      "Trainable params: 87,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras\n",
    "loaded_model = tensorflow.keras.models.load_model('D:/mini project/Models/Emotion_Voice_Detection_Model.h5')\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dx2PEX6xwQbe",
    "outputId": "0d1c4383-fb94-432e-f5b5-63dd4697562f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3499 - accuracy: 0.8589\n",
      " accuracy: 85.89%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = loaded_model.evaluate(x_testcnn, y_test)\n",
    "print(\" accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dvkiXj9gp-WP",
    "outputId": "2d9fabc4-c8e3-4fce-dfd6-aeef76b3fd80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 40, 1)\n",
      "Prediction is   [1]\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "data, sampling_rate = librosa.load('D:/mini project/Models/examples2.wav', res_type='kaiser_fast')\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
    "\n",
    "x = np.expand_dims(mfccs, axis=-1)\n",
    "\n",
    "x = np.expand_dims(x, axis=0)\n",
    "print(x.shape)\n",
    "predictions = loaded_model.predict_classes(x)\n",
    "print( \"Prediction is\", \" \",predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LqURVRQ2ZKsC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V3lXFzH5r94s"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "EmotionRecognition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
